{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoher Ghadyali\n",
    "\n",
    "Data Science 2016\n",
    "\n",
    "Model Iteration 2 - Warmup Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook initially repeats the work done in the DataQuest \"Improving your submission\" mission with some slight modifications. I disregarded family size and family ID based off of the bar plot shown in the mission that plots each field by its p-value. So in the end, my train dataset had the additional fields (after cleaning the data in the same way as model_iteration_1.ipynb) of nameLength (the length of the person's name and potentially an indicator of wealth), title (also an indicator of wealth), and isChild which is a field I created that is 1 if the age of the passenger is less than or equal to 5 and 0 otherwise.\n",
    "\n",
    "Below is what the train dataset looks like now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>Title</th>\n",
       "      <th>isChild</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>1</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>1</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>1</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>1</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name Sex        Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris   0  22.000000      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.000000      1   \n",
       "2                               Heikkinen, Miss. Laina   1  26.000000      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.000000      1   \n",
       "4                             Allen, Mr. William Henry   0  35.000000      0   \n",
       "5                                     Moran, Mr. James   0  29.699118      0   \n",
       "6                              McCarthy, Mr. Timothy J   0  54.000000      0   \n",
       "7                       Palsson, Master. Gosta Leonard   0   2.000000      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   1  27.000000      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)   1  14.000000      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut   1   4.000000      1   \n",
       "11                            Bonnell, Miss. Elizabeth   1  58.000000      0   \n",
       "12                      Saundercock, Mr. William Henry   0  20.000000      0   \n",
       "13                         Andersson, Mr. Anders Johan   0  39.000000      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina   1  14.000000      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)    1  55.000000      0   \n",
       "16                                Rice, Master. Eugene   0   2.000000      4   \n",
       "17                        Williams, Mr. Charles Eugene   0  29.699118      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...   1  31.000000      1   \n",
       "19                             Masselmani, Mrs. Fatima   1  29.699118      0   \n",
       "20                                Fynney, Mr. Joseph J   0  35.000000      0   \n",
       "21                               Beesley, Mr. Lawrence   0  34.000000      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"   1  15.000000      0   \n",
       "23                        Sloper, Mr. William Thompson   0  28.000000      0   \n",
       "24                       Palsson, Miss. Torborg Danira   1   8.000000      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...   1  38.000000      1   \n",
       "26                             Emir, Mr. Farred Chehab   0  29.699118      0   \n",
       "27                      Fortune, Mr. Charles Alexander   0  19.000000      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"   1  29.699118      0   \n",
       "29                                 Todoroff, Mr. Lalio   0  29.699118      0   \n",
       "..                                                 ...  ..        ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward   0  21.000000      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...   1  48.000000      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"   1  29.699118      8   \n",
       "864                             Gill, Mr. John William   0  24.000000      0   \n",
       "865                           Bystrom, Mrs. (Karolina)   1  42.000000      0   \n",
       "866                       Duran y More, Miss. Asuncion   1  27.000000      1   \n",
       "867               Roebling, Mr. Washington Augustus II   0  31.000000      0   \n",
       "868                        van Melkebeke, Mr. Philemon   0  29.699118      0   \n",
       "869                    Johnson, Master. Harold Theodor   0   4.000000      1   \n",
       "870                                  Balkic, Mr. Cerin   0  26.000000      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   1  47.000000      1   \n",
       "872                           Carlsson, Mr. Frans Olof   0  33.000000      0   \n",
       "873                        Vander Cruyssen, Mr. Victor   0  47.000000      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)   1  28.000000      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"   1  15.000000      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian   0  20.000000      0   \n",
       "877                               Petroff, Mr. Nedelio   0  19.000000      0   \n",
       "878                                 Laleff, Mr. Kristo   0  29.699118      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)   1  56.000000      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)   1  25.000000      0   \n",
       "881                                 Markun, Mr. Johann   0  33.000000      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika   1  22.000000      0   \n",
       "883                      Banfield, Mr. Frederick James   0  28.000000      0   \n",
       "884                             Sutehall, Mr. Henry Jr   0  25.000000      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)   1  39.000000      0   \n",
       "886                              Montvila, Rev. Juozas   0  27.000000      0   \n",
       "887                       Graham, Miss. Margaret Edith   1  19.000000      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"   1  29.699118      1   \n",
       "889                              Behr, Mr. Karl Howell   0  26.000000      0   \n",
       "890                                Dooley, Mr. Patrick   0  32.000000      0   \n",
       "\n",
       "     Parch            Ticket      Fare        Cabin Embarked  NameLength  \\\n",
       "0        0         A/5 21171    7.2500          NaN        0          23   \n",
       "1        0          PC 17599   71.2833          C85        1          51   \n",
       "2        0  STON/O2. 3101282    7.9250          NaN        0          22   \n",
       "3        0            113803   53.1000         C123        0          44   \n",
       "4        0            373450    8.0500          NaN        0          24   \n",
       "5        0            330877    8.4583          NaN        2          16   \n",
       "6        0             17463   51.8625          E46        0          23   \n",
       "7        1            349909   21.0750          NaN        0          30   \n",
       "8        2            347742   11.1333          NaN        0          49   \n",
       "9        0            237736   30.0708          NaN        1          35   \n",
       "10       1           PP 9549   16.7000           G6        0          31   \n",
       "11       0            113783   26.5500         C103        0          24   \n",
       "12       0         A/5. 2151    8.0500          NaN        0          30   \n",
       "13       5            347082   31.2750          NaN        0          27   \n",
       "14       0            350406    7.8542          NaN        0          36   \n",
       "15       0            248706   16.0000          NaN        0          32   \n",
       "16       1            382652   29.1250          NaN        2          20   \n",
       "17       0            244373   13.0000          NaN        0          28   \n",
       "18       0            345763   18.0000          NaN        0          55   \n",
       "19       0              2649    7.2250          NaN        1          23   \n",
       "20       0            239865   26.0000          NaN        0          20   \n",
       "21       0            248698   13.0000          D56        0          21   \n",
       "22       0            330923    8.0292          NaN        2          27   \n",
       "23       0            113788   35.5000           A6        0          28   \n",
       "24       1            349909   21.0750          NaN        0          29   \n",
       "25       5            347077   31.3875          NaN        0          57   \n",
       "26       0              2631    7.2250          NaN        1          23   \n",
       "27       2             19950  263.0000  C23 C25 C27        0          30   \n",
       "28       0            330959    7.8792          NaN        2          29   \n",
       "29       0            349216    7.8958          NaN        0          19   \n",
       "..     ...               ...       ...          ...      ...         ...   \n",
       "861      0             28134   11.5000          NaN        0          27   \n",
       "862      0             17466   25.9292          D17        0          51   \n",
       "863      2          CA. 2343   69.5500          NaN        0          33   \n",
       "864      0            233866   13.0000          NaN        0          22   \n",
       "865      0            236852   13.0000          NaN        0          24   \n",
       "866      0     SC/PARIS 2149   13.8583          NaN        1          28   \n",
       "867      0          PC 17590   50.4958          A24        0          36   \n",
       "868      0            345777    9.5000          NaN        0          27   \n",
       "869      1            347742   11.1333          NaN        0          31   \n",
       "870      0            349248    7.8958          NaN        0          17   \n",
       "871      1             11751   52.5542          D35        0          48   \n",
       "872      0               695    5.0000  B51 B53 B55        0          24   \n",
       "873      0            345765    9.0000          NaN        0          27   \n",
       "874      0         P/PP 3381   24.0000          NaN        1          37   \n",
       "875      0              2667    7.2250          NaN        1          32   \n",
       "876      0              7534    9.8458          NaN        0          29   \n",
       "877      0            349212    7.8958          NaN        0          20   \n",
       "878      0            349217    7.8958          NaN        0          18   \n",
       "879      1             11767   83.1583          C50        1          45   \n",
       "880      1            230433   26.0000          NaN        0          44   \n",
       "881      0            349257    7.8958          NaN        0          18   \n",
       "882      0              7552   10.5167          NaN        0          28   \n",
       "883      0  C.A./SOTON 34068   10.5000          NaN        0          29   \n",
       "884      0   SOTON/OQ 392076    7.0500          NaN        0          22   \n",
       "885      5            382652   29.1250          NaN        2          36   \n",
       "886      0            211536   13.0000          NaN        0          21   \n",
       "887      0            112053   30.0000          B42        0          28   \n",
       "888      2        W./C. 6607   23.4500          NaN        0          40   \n",
       "889      0            111369   30.0000         C148        1          21   \n",
       "890      0            370376    7.7500          NaN        2          19   \n",
       "\n",
       "    Title  isChild  \n",
       "0       1        0  \n",
       "1       3        0  \n",
       "2       2        0  \n",
       "3       3        0  \n",
       "4       1        0  \n",
       "5       1        0  \n",
       "6       1        0  \n",
       "7       4        1  \n",
       "8       3        0  \n",
       "9       3        0  \n",
       "10      2        1  \n",
       "11      2        0  \n",
       "12      1        0  \n",
       "13      1        0  \n",
       "14      2        0  \n",
       "15      3        0  \n",
       "16      4        1  \n",
       "17      1        0  \n",
       "18      3        0  \n",
       "19      3        0  \n",
       "20      1        0  \n",
       "21      1        0  \n",
       "22      2        0  \n",
       "23      1        0  \n",
       "24      2        0  \n",
       "25      3        0  \n",
       "26      1        0  \n",
       "27      1        0  \n",
       "28      2        0  \n",
       "29      1        0  \n",
       "..    ...      ...  \n",
       "861     1        0  \n",
       "862     3        0  \n",
       "863     2        0  \n",
       "864     1        0  \n",
       "865     3        0  \n",
       "866     2        0  \n",
       "867     1        0  \n",
       "868     1        0  \n",
       "869     4        1  \n",
       "870     1        0  \n",
       "871     3        0  \n",
       "872     1        0  \n",
       "873     1        0  \n",
       "874     3        0  \n",
       "875     2        0  \n",
       "876     1        0  \n",
       "877     1        0  \n",
       "878     1        0  \n",
       "879     3        0  \n",
       "880     3        0  \n",
       "881     1        0  \n",
       "882     2        0  \n",
       "883     1        0  \n",
       "884     1        0  \n",
       "885     3        0  \n",
       "886     6        0  \n",
       "887     2        0  \n",
       "888     2        0  \n",
       "889     1        0  \n",
       "890     1        0  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "%matplotlib inline\n",
    "\n",
    "titanic = pandas.read_csv(\"train.csv\")\n",
    "\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end \n",
    "    # with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def clean_data(df):\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].mean())\n",
    "\n",
    "    df.loc[df[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "    df.loc[df[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    df.loc[df[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    df.loc[df[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    df.loc[df[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "    df[\"NameLength\"] = df[\"Name\"].apply(lambda x: len(x))\n",
    "    titles = df[\"Name\"].apply(get_title)\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \n",
    "                     \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Dona\": 10, \"Sir\": 9, \"Capt\": 7, \n",
    "                     \"Ms\": 2}\n",
    "    for k,v in title_mapping.items():\n",
    "        titles[titles == k] = v\n",
    "\n",
    "    # Add in the title column.\n",
    "    df[\"Title\"] = titles\n",
    "    df[\"isChild\"] = 0\n",
    "    df.loc[df[\"Age\"] <= 5, \"isChild\"] = 1\n",
    "    return df\n",
    "\n",
    "titanic = clean_data(titanic)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that was shown in the mission that I thought was really cool was the ability to determine which fields in the data are the most important to train off of. Using sklearn's SelectKBest function, we determine the p-value and convert it to a score by taking the negative log base 10, which means the highest scores are the lowest p-values. This quickly tells us what is important to focus on and what isn't. \n",
    "\n",
    "I was curious about how this function worked so I did some research and SelectKBest takes as input a score function, which in this case is f_classif which computes the f-value. According to Wikipedia, the f-value is the ratio of two mean square values and if there is a relationship between the field and the result, you would expect an f-value close to 1. I would be interested in learning more about this and how it works.\n",
    "\n",
    "The resulting plot for all of the fields in the dataset so far is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass:  24.5956714208\n",
      "Sex:  68.8519942529\n",
      "Age:  1.42925766052\n",
      "SibSp:  0.534254502442\n",
      "Parch:  1.82976042906\n",
      "Fare:  14.2132351418\n",
      "Embarked:  2.85130099045\n",
      "NameLength:  23.6931901615\n",
      "Title:  26.9833860721\n",
      "isChild:  5.17975037692\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAE2CAYAAACqSMMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEI7IqJDEtoRER2S0I6I6JCEdkREh/x/27A41H3qg2QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110fa02d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"NameLength\", \"Title\", \"isChild\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "for i in range(0, len(predictors)):\n",
    "    print predictors[i] + ': ', scores[i]\n",
    "\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that, in order, Sex, Title, Pclass, NameLength, Fare, and isChild are the most important features. It is interesting to me that we focused on age in building all of our models when it has a very low score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to pick a model and cross validate it to see how accurate it is in the splitting the train data in test-train sets. Again, following the mission, we start with a random forest classifier which randomly creates decision trees and averages the output of the trees. In this case, we are using 150 of these random decision tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.810325476992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\", \"NameLength\", \"isChild\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print \"Accuracy\", scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cross-validated our model, we train it on the train data using the important predictors from SelectKBest and test the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test = pandas.read_csv(\"test.csv\")\n",
    "titanic_test = clean_data(titanic_test)\n",
    "\n",
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"model_iteration_2_rev1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting score on Kaggle was 0.77512 which is the same score we got at the end of model_iteration_1.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of the mission uses an ensemble of different classifiers. We know we have some form of linear relationship between the predictors from SelectKBest and we use a gradient boosting classifier on all of the fields. A gradient boosting classifier trains decision trees one after another which means overfitting is a problem. This is why we only use 25 in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.809203142536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:40: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting \n",
    "# classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \n",
    "    \"Parch\", \"Fare\", \"Embarked\", \"NameLength\", \"Title\", \"isChild\"]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"Title\", \"NameLength\", \"isChild\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print \"Accuracy\", accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cross-validated our model, we predict off of the test data set using each algorithm. We have a more complex ensembling scheme here where we weight the output of the gradient boosting classifier higher than the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "predictions = predictions.astype(int)\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"model_iteration_2_rev2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this model, the Kaggle score was 0.79426 which is the best score I have achieved throughout this project. I believe this is in part because we made the logistic regression more accurate and, by reducing the fields to only the ones we know are important, created a less overfit and more generalizable model. I also think using the gradient boosting classifier in addition to the logistic regression worked well because they are very different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this notebook is working on my own idea which builds off of something we discussed in class on Friday, Jan 29, 2016. The problem with using linear models is that the more fields you train off of, the more complex the model, and the more likely it is that the model will overfit to fields that are not actually significant which will increase accuracy on your train dataset but is not generalizable to the test dataset and will subsequently produce a lower score. So in looking at the bar plot from SelectKBest() generated above, I realized that if we disregard Age, Sibsp, and Parch, the least three significant fields are Fare, Embarked, and isChild. I wanted to know if aggregating these fields would be significant.\n",
    "\n",
    "So in the three code blocks below, I compute the survival rate if passengers embarked in Southampton, Cherbourg, or Queenstown, if passengers paid under 10 pounds for their ticket, between 10 and 20 pounds, betwen 20 and 30 pounds, between 30 and 65 pounds, and between 65 and 512 pounds (the max fare a passenger paid in the train dataset on the Titanic), and if passengers were under the age of 5 (classified as Child) or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked in Southampton Survival Rate\n",
      "0.339009287926\n",
      "Embarked in Cherbourg Survival Rate\n",
      "0.553571428571\n",
      "Embarked in Queenstown Survival Rate\n",
      "0.38961038961\n"
     ]
    }
   ],
   "source": [
    "print \"Embarked in Southampton Survival Rate\"\n",
    "survival0 = len(titanic[(titanic[\"Embarked\"] == 0) & (titanic[\"Survived\"] == 1)])/float(len(titanic[titanic[\"Embarked\"] == 0]))\n",
    "print survival0\n",
    "print \"Embarked in Cherbourg Survival Rate\"\n",
    "survival1 = len(titanic[(titanic[\"Embarked\"] == 1) & (titanic[\"Survived\"] == 1)])/float(len(titanic[titanic[\"Embarked\"] == 1])) \n",
    "print survival1\n",
    "print \"Embarked in Queenstown Survival Rate\"\n",
    "survival2 = len(titanic[(titanic[\"Embarked\"] == 2) & (titanic[\"Survived\"] == 1)])/float(len(titanic[titanic[\"Embarked\"] == 2]))\n",
    "print survival2\n",
    "\n",
    "survivalEmbarked = [survival0, survival1, survival2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Rate for Fares <=10\n",
      "0.199404761905\n",
      "Survival Rate for Fares >10 & <=20\n",
      "0.424581005587\n",
      "Survival Rate for Fares >20 & <=30\n",
      "0.443661971831\n",
      "Survival Rate for Fares >30 & <=65\n",
      "0.483050847458\n",
      "Survival Rate for Fares >65 & <= 512.3292\n",
      "0.581196581197\n"
     ]
    }
   ],
   "source": [
    "print \"Survival Rate for Fares <=10\"\n",
    "tot = titanic[titanic[\"Fare\"] <= 10]\n",
    "survived = tot[tot[\"Survived\"] == 1]\n",
    "survivalFare1 = len(survived) / float(len(tot))\n",
    "print survivalFare1\n",
    "print \"Survival Rate for Fares >10 & <=20\"\n",
    "tot = titanic[(titanic[\"Fare\"] > 10) & (titanic[\"Fare\"] <= 20)]\n",
    "survived = tot[tot[\"Survived\"] == 1]\n",
    "survivalFare2 = len(survived) / float(len(tot))\n",
    "print survivalFare2\n",
    "print \"Survival Rate for Fares >20 & <=30\"\n",
    "tot = titanic[(titanic[\"Fare\"] > 20) & (titanic[\"Fare\"] <= 30)]\n",
    "survived = tot[tot[\"Survived\"] == 1]\n",
    "survivalFare3 = len(survived) / float(len(tot))\n",
    "print survivalFare3\n",
    "print \"Survival Rate for Fares >30 & <=65\"\n",
    "tot = titanic[(titanic[\"Fare\"] > 30) & (titanic[\"Fare\"] <= 65)]\n",
    "survived = tot[tot[\"Survived\"] == 1]\n",
    "survivalFare4 = len(survived) / float(len(tot))\n",
    "print survivalFare4\n",
    "print \"Survival Rate for Fares >65 & <=\", titanic[\"Fare\"].max()\n",
    "tot = titanic[(titanic[\"Fare\"] > 30) & (titanic[\"Fare\"] <= titanic[\"Fare\"].max())]\n",
    "survived = tot[tot[\"Survived\"] == 1]\n",
    "survivalFare5 = len(survived) / float(len(tot))\n",
    "print survivalFare5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Rate for Age >5\n",
      "0.367178276269\n",
      "Survival Rate for Age <=5\n",
      "0.704545454545\n"
     ]
    }
   ],
   "source": [
    "print \"Survival Rate for Age >5\"\n",
    "tot = titanic[titanic[\"isChild\"] == 0]\n",
    "survived = tot[tot[\"Survived\"] == 1]\n",
    "survivalNotChild = len(survived) / float(len(tot))\n",
    "print survivalNotChild\n",
    "print \"Survival Rate for Age <=5\"\n",
    "tot = titanic[titanic[\"isChild\"] == 1]\n",
    "survived = tot[tot[\"Survived\"] == 1]\n",
    "survivalChild = len(survived) / float(len(tot))\n",
    "print survivalChild\n",
    "\n",
    "survivalChild = [survivalNotChild, survivalChild]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not very proud of the method used in this next code block but it works. I am sure there is a cleaner and better way to do this. Basically, this code is the equivalent of finding all passengers who, for example, boarded in Southampton, paid less than 10 pounds for fare, and are not children. I created a new field called aggregate that simply averages that person's chance of surviving using the fact that the survival rate for embarking in Southamption is 33.9%, the survival rate for fares <= 10 is 19.94%, and the survival rate for passengers over the age of 5 is 36.72%. I do this for all passnegers in hopes to get more information about their chance of surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_aggregate(df):\n",
    "    df[\"Aggregate\"] = 0\n",
    "    #loops through all 3 embarked categories, 0 is Southampton, 1 is Cherbourg, 2 is Queenstown\n",
    "    for i in range(0, 3):\n",
    "        #loops through isNotChild and isChild categories, computes agg first for all non-Children and then for children\n",
    "        for j in range(0, 2):\n",
    "            agg = (survivalEmbarked[i] + survivalFare1 + survivalChild[j])/float(3)\n",
    "            df.loc[((df[\"Embarked\"] == i) & (df[\"Fare\"] <= 10) & (df[\"isChild\"] == j)), \"Aggregate\"] = agg\n",
    "            agg = (survivalEmbarked[i] + survivalFare2 + survivalChild[j])/float(3)\n",
    "            df.loc[((df[\"Embarked\"] == i) & (df[\"Fare\"] > 10) & (df[\"Fare\"] <= 20) & (df[\"isChild\"] == j)), \"Aggregate\"] = agg\n",
    "            agg = (survivalEmbarked[i] + survivalFare3 + survivalChild[j])/float(3)\n",
    "            df.loc[((df[\"Embarked\"] == i) & (df[\"Fare\"] > 20) & (df[\"Fare\"] <= 30) & (df[\"isChild\"] == j)), \"Aggregate\"] = agg\n",
    "            agg = (survivalEmbarked[i] + survivalFare4 + survivalChild[j])/float(3)\n",
    "            df.loc[((df[\"Embarked\"] == i) & (df[\"Fare\"] > 30) & (df[\"Fare\"] <= 65 ) & (df[\"isChild\"] == j)), \"Aggregate\"] = agg\n",
    "            agg = (survivalEmbarked[i] + survivalFare5 + survivalChild[j])/float(3)\n",
    "            df.loc[((df[\"Embarked\"] == i) & (df[\"Fare\"] > 65) & (df[\"Fare\"] <= df[\"Fare\"].max() ) & (df[\"isChild\"] == j)), \"Aggregate\"] = agg\n",
    "    return df\n",
    "\n",
    "titanic = compute_aggregate(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My next step was to determine if the field I had created was now important and scored highly using SelectKBest(). Using all of the fields, I plot the predictors and their scores below, just the same as I did above but with the new Aggregate field added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass:  24.5956714208\n",
      "Sex:  68.8519942529\n",
      "Age:  1.42925766052\n",
      "SibSp:  0.534254502442\n",
      "Parch:  1.82976042906\n",
      "Fare:  14.2132351418\n",
      "Embarked:  2.85130099045\n",
      "NameLength:  23.6931901615\n",
      "Title:  26.9833860721\n",
      "isChild:  5.17975037692\n",
      "Aggregate:  28.4125829099\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAE2CAYAAACqSMMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111995d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"NameLength\", \"Title\", \"isChild\", \"Aggregate\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "for i in range(0, len(predictors)):\n",
    "    print predictors[i] + ': ', scores[i]\n",
    "\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is really interesting because I was expecting that even if the Aggregate field worked well, it could at most have a score that is a summation of the scores produced by Fare, Embarked, and isChild which totals 22.24. The score of Aggregate is actually 28.41 which exceeds the sum of the three scores by 6.17. I am really curious about this and how this happened. I briefly tried playing with weighting the fields differently and how they affected the calculated agg but I found that I could only produce very little change in Aggregate's score or decrease it. I would like to investigate and play with this further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was now to put my new and important Aggregate field into use. I used a random forest classifier and this was really just a benchmark to see if there would be any significant change in accuracy or Kaggle score. My motivation for trying this was to improve the score achieved by linear models, which I try after testing the rfc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.805836139169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Title\", \"NameLength\", \"Aggregate\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print \"Accuracy\", scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we apply our compute_aggregate function to the test data and one important thing to note here is that we are taking the survival rates we found in the training data and applying it to the entire test dataset. This is our only option but it could also be a reason for us to score less well. It might be possible that while only 33.9% of passengers who embarked in Southampton survived, in the test data set it could be that 50% of the passengers who embarked in Southamption survived and we have no way to account for this in the Aggregate field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test = compute_aggregate(titanic_test)\n",
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"model_iteration_2_rev3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved a Kaggle score of 0.77033 which is actually about 0.005 lower then what was achieved by using rfc earlier in this notebook. One possible explanation for this is that we used more fields previously because we were using Fare and isChild and we replaced these with Aggregate. The other thing is that Aggregate now smooths out the predictions that were made off of Fare and isChild. It could be the case that averaging the data works less well for random forest which intuitively makes sense to me since it is randomly generating decision trees and I am smoothing out the metrics chosen for certain decisions involving Fare and isChild."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so let's use the Aggregate field in a place where we expect it to actually matter now, which is in a linear model, like LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.785634118967\n"
     ]
    }
   ],
   "source": [
    "alg = LogisticRegression(random_state=1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print \"Accuracy\", scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"model_iteration_2_rev4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a Kaggle score of 0.77033. If you look back at model_iteration_1.ipynb, when we used the logistic regression model, we had a Kaggle score of 0.75120 so by creating and using the Aggregate field, we see a 1.913% improvement which is good and means we have a method to improve linear models.\n",
    "\n",
    "More domain knowledge and more knowledge of the data itself and what is and is not important, beyond just using SelectKBest would probably help aggregate data in a way that is effective, improving linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I tried using the Aggregate field on our previous ensemble method. I was hoping that aggregate would produce a better logistic regression and this could in turn improve the score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.812570145903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \n",
    "    \"Parch\", \"Fare\", \"Embarked\", \"NameLength\", \"Title\", \"isChild\", \"Aggregate\"]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Title\", \"NameLength\", \"Aggregate\"]]\n",
    "]\n",
    "\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    for alg, predictors in algorithms:\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print \"Accuracy\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "predictions = predictions.astype(int)\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"model_iteration_2_rev5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resultig Kaggle score was 0.77990 which is lower than what we achieved earlier in this notebook. One possibility is that when we ensemble, our classifiers have to be similar in accuracy and while we improved the accuracy of the logistic regression model, the gradient boosting classifier might not have increased in accuracy because of the Aggregate field. Another factor is that we weight gradient boosting more but we didn't improve that classifier at all so we are not seeing improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further exploration I would like to explore SelectKBest() which I kind of took as the end-all be-all of feature selection in this project and look for alternatives. I would really like to explore situations where SelectKBest() and another feature-selection tool differ and figure out why they differ. I would also really like to play around with changing the parameters on my Aggregate field which right now weights each field that it aggregates evenly. One method that I am thinking of is possibly using the p-value or the score to determine the weight that a given field should have when aggregating. One additional thing that I would like to do with more time is actually clean up this model a bit and rewrite my helper functions in more efficient, cleaner, and more self-explanatory ways."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
